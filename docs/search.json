[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nivan Vora",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog/project1/hw1_questions.html",
    "href": "blog/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\n_to do: Participants were split into a control group and a treatment group:\n\nControl group: Received a standard letter with no mention of a match.\nTreatment group: Received a letter stating that a “concerned fellow member” would match their donation. These individuals were randomly assigned to one of three match ratios:\n\n1:1 — Every $1 donated is matched with $1.\n2:1 — Every $1 donated is matched with $2.\n3:1 — Every $1 donated is matched with $3.\n\n\nAdditional randomization dimensions included: - Maximum matching grant size: $25,000, $50,000, $100,000, or unspecified. - Suggested donation amount: Equal to, 1.25×, or 1.5× of the individual’s previous highest donation.\nKey findings from the study: - Mentioning a matching grant increased donation response rate by 22% and revenue per solicitation by 19%. - Surprisingly, higher match ratios (2:1, 3:1) did not yield significantly greater giving than the 1:1 match. - Heterogeneous treatment effects were found—donors in “red states” (those that voted for George W. Bush in 2004) responded significantly more to the matching grant than those in “blue states”.\nThis experiment provides robust evidence for the effectiveness of matching grants in charitable giving and raises important questions about donor psychology, price sensitivity, and the contextual framing of donation requests."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#introduction",
    "href": "blog/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\n_to do: Participants were split into a control group and a treatment group:\n\nControl group: Received a standard letter with no mention of a match.\nTreatment group: Received a letter stating that a “concerned fellow member” would match their donation. These individuals were randomly assigned to one of three match ratios:\n\n1:1 — Every $1 donated is matched with $1.\n2:1 — Every $1 donated is matched with $2.\n3:1 — Every $1 donated is matched with $3.\n\n\nAdditional randomization dimensions included: - Maximum matching grant size: $25,000, $50,000, $100,000, or unspecified. - Suggested donation amount: Equal to, 1.25×, or 1.5× of the individual’s previous highest donation.\nKey findings from the study: - Mentioning a matching grant increased donation response rate by 22% and revenue per solicitation by 19%. - Surprisingly, higher match ratios (2:1, 3:1) did not yield significantly greater giving than the 1:1 match. - Heterogeneous treatment effects were found—donors in “red states” (those that voted for George W. Bush in 2004) responded significantly more to the matching grant than those in “blue states”.\nThis experiment provides robust evidence for the effectiveness of matching grants in charitable giving and raises important questions about donor psychology, price sensitivity, and the contextual framing of donation requests."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#this-project-seeks-to-replicate-their-results.",
    "href": "blog/project1/hw1_questions.html#this-project-seeks-to-replicate-their-results.",
    "title": "A Replication of Karlan and List (2007)",
    "section": "This project seeks to replicate their results.",
    "text": "This project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#data",
    "href": "blog/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport numpy as np\nimport pandas as pd\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_describe = df.describe()\ndf.describe(include='all')\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nunique\nNaN\nNaN\n4\nNaN\nNaN\n5\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\ntop\nNaN\nNaN\nControl\nNaN\nNaN\nControl\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nfreq\nNaN\nNaN\n16687\nNaN\nNaN\n16687\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nmean\n0.666813\n0.333187\nNaN\n0.222311\n0.222211\nNaN\n0.166723\n0.166623\n0.166723\n0.166743\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\nNaN\n0.415803\n0.415736\nNaN\n0.372732\n0.372643\n0.372732\n0.372750\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n11 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport pyreadstat\n\ndf,_  = pyreadstat.read_dta(\"karlan_list_2007.dta\")\n\nvariables_to_test = ['mrm2', 'years', 'ave_hh_sz', 'female', 'couple']\n\nfor var in variables_to_test:\n    df[var] = pd.to_numeric(df[var], errors='coerce')\n\nresults = []\n\nfor var in variables_to_test:\n    treat = df[df['treatment'] == 1][var].dropna()\n    control = df[df['treatment'] == 0][var].dropna()\n\n    t_stat, p_val_ttest = ttest_ind(treat, control, nan_policy='omit')\n\n    reg_df = df[['treatment', var]].dropna()\n    X = sm.add_constant(reg_df['treatment'])\n    y = reg_df[var]\n    model = sm.OLS(y, X).fit()\n    coef = model.params['treatment']\n    t_val_reg = model.tvalues['treatment']\n    p_val_reg = model.pvalues['treatment']\n\n    results.append({\n        'variable': var,\n        'mean_treat': round(treat.mean(), 3),\n        'mean_control': round(control.mean(), 3),\n        't_stat_ttest': round(t_stat, 3),\n        'p_value_ttest': round(p_val_ttest, 3),\n        'regression_coef': round(coef, 3),\n        't_stat_regression': round(t_val_reg, 3),\n        'p_value_regression': round(p_val_reg, 3),\n        'significant_95pct': p_val_ttest &lt; 0.05 and p_val_reg &lt; 0.05\n    })\n\nresults_df = pd.DataFrame(results)\nprint(results_df)\n\n    variable  mean_treat  mean_control  t_stat_ttest  p_value_ttest  \\\n0       mrm2      13.012        12.998         0.119          0.905   \n1      years       6.078         6.136        -1.103          0.270   \n2  ave_hh_sz       2.430         2.427         0.824          0.410   \n3     female       0.275         0.283        -1.758          0.079   \n4     couple       0.091         0.093        -0.584          0.559   \n\n   regression_coef  t_stat_regression  p_value_regression  significant_95pct  \n0            0.014              0.119               0.905              False  \n1           -0.058             -1.103               0.270              False  \n2            0.003              0.824               0.410              False  \n3           -0.008             -1.758               0.079              False  \n4           -0.002             -0.584               0.559              False  \n\n\nTo evaluate the validity of the randomization, we tested several non-outcome variables — such as months since last donation, years since initial donation, gender, and household characteristics — to see whether there were statistically significant differences between the treatment and control groups.\nFor each variable, we conducted: - A two-sample t-test, and - A linear regression of the form variable ~ treatment.\nAcross all tested variables, none showed statistically significant differences between the treatment and control groups at the 95% confidence level (p-values &gt; 0.05). This confirms that the treatment assignment was successfully randomized."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#experimental-results",
    "href": "blog/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean()\ndonation_labels = ['Control', 'Treatment']\n\nplt.figure(figsize=(6, 4))\nplt.bar(donation_labels, donation_rates, color=['gray', 'skyblue'])\nplt.title(\"Proportion of People Who Donated\")\nplt.ylabel(\"Donation Rate\")\nplt.ylim(0, 0.03)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport pyreadstat\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ntreat = df[df['treatment'] == 1]['gave'].dropna()\ncontrol = df[df['treatment'] == 0]['gave'].dropna()\nt_stat, p_val = ttest_ind(treat, control, nan_policy='omit')\n\nreg_df = df[['treatment', 'gave']].dropna()\nX = sm.add_constant(reg_df['treatment'])\ny = reg_df['gave']\nmodel = sm.OLS(y, X).fit()\n\nt_test_result = {\n    \"t_statistic\": round(t_stat, 4),\n    \"p_value\": round(p_val, 4),\n    \"mean_treatment\": round(treat.mean(), 4),\n    \"mean_control\": round(control.mean(), 4)\n}\n\nregression_summary = model.summary()\n\nt_test_result, regression_summary\n\n({'t_statistic': 3.1014,\n  'p_value': 0.0019,\n  'mean_treatment': 0.022,\n  'mean_control': 0.0179},\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   gave   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     9.618\n Date:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\n Time:                        20:32:02   Log-Likelihood:                 26630.\n No. Observations:               50083   AIC:                        -5.326e+04\n Df Residuals:                   50081   BIC:                        -5.324e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const          0.0179      0.001     16.225      0.000       0.016       0.020\n treatment      0.0042      0.001      3.101      0.002       0.002       0.007\n ==============================================================================\n Omnibus:                    59814.280   Durbin-Watson:                   2.005\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\n Skew:                           6.740   Prob(JB):                         0.00\n Kurtosis:                      46.440   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport pyreadstat\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_clean = df[['treatment', 'gave']].dropna()\n\nprobit_model = sm.Probit(df_clean['gave'], sm.add_constant(df_clean['treatment'])).fit(disp=False)\n\nsummary_stats = {\n    \"Pseudo R-squared\": probit_model.prsquared,\n    \"Log-Likelihood\": probit_model.llf,\n    \"AIC\": probit_model.aic,\n    \"BIC\": probit_model.bic,\n    \"Observations\": int(probit_model.nobs),\n    \"Coef (treatment)\": probit_model.params['treatment'],\n    \"Std Err (treatment)\": probit_model.bse['treatment'],\n    \"z-stat (treatment)\": probit_model.tvalues['treatment'],\n    \"P&gt;|z| (treatment)\": probit_model.pvalues['treatment'],\n    \"95% CI (treatment)\": probit_model.conf_int().loc['treatment'].tolist()\n}\n\nmarginal_effect = probit_model.get_margeff(at='overall').summary_frame().loc['treatment', 'dy/dx']\n\nsummary_stats[\"Marginal Effect (dy/dx)\"] = marginal_effect\n\nsummary_stats\n\n{'Pseudo R-squared': 0.0009782722838191926,\n 'Log-Likelihood': -5030.501164143209,\n 'AIC': 10065.002328286419,\n 'BIC': 10082.645202102685,\n 'Observations': 50083,\n 'Coef (treatment)': 0.08678462244745852,\n 'Std Err (treatment)': 0.027878757437573513,\n 'z-stat (treatment)': 3.1129300737949963,\n 'P&gt;|z| (treatment)': 0.001852399014778513,\n '95% CI (treatment)': [0.03214326193608627, 0.14142598295883077],\n 'Marginal Effect (dy/dx)': 0.004313211579633209}\n\n\nThis Probit model confirms that individuals who received a matched donation offer were significantly more likely to donate. The marginal effect suggests a 0.43 percentage point increase in the probability of donating—small but statistically significant (p &lt; 0.01).\n🧪 Statistical Approach & Interpretation\nIn this analysis, we test whether being assigned to the treatment group (which received a matched donation offer) significantly affects the likelihood of making a charitable donation.\nWe use two methods: - T-test: Compares the mean donation rates between treatment and control groups. - Bivariate Linear Regression: Regresses the binary outcome gave on the treatment variable to estimate the average treatment effect.\n📊 Key Results - The mean donation rate in the treatment group is higher than in the control group. - Both the t-test and regression confirm this difference is statistically significant at the 5% level. - The effect size is modest (a few tenths of a percentage point), but positive and consistent across methods.\n📌 Interpretation These results suggest that offering a matching donation increases the likelihood of giving. Even though the increase is small, it is statistically meaningful and aligns with behavioral insights: people respond to perceived value enhancement when their donation is matched.\nThis supports the idea that subtle psychological nudges—like matched giving—can effectively influence charitable behavior. The very low R-squared value is typical for binary outcome models with limited predictors and does not reduce the credibility of the treatment effect.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nimport pandas as pd\nfrom scipy.stats import ttest_ind\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf['ratio_str'] = df['ratio'].replace({1: '1:1', 2: '2:1', 3: '3:1'})\n\nmatch_df = df[df['treatment'] == 1][['gave', 'ratio_str']].dropna()\n\ngave_1to1 = match_df[match_df['ratio_str'] == '1:1']['gave']\ngave_2to1 = match_df[match_df['ratio_str'] == '2:1']['gave']\ngave_3to1 = match_df[match_df['ratio_str'] == '3:1']['gave']\n\ntests = {\n    \"2:1 vs 1:1\": ttest_ind(gave_2to1, gave_1to1, nan_policy='omit'),\n    \"3:1 vs 1:1\": ttest_ind(gave_3to1, gave_1to1, nan_policy='omit'),\n    \"3:1 vs 2:1\": ttest_ind(gave_3to1, gave_2to1, nan_policy='omit')\n}\n\nprint(\"=== T-Test Results on Match Ratios ===\")\nfor label, result in tests.items():\n    t_stat, p_val = result\n    significance = \"✅ Significant\" if p_val &lt; 0.05 else \"❌ Not Significant\"\n    print(f\"{label:&lt;15} | t = {t_stat:.4f}, p = {p_val:.4f} | {significance}\")\n\n=== T-Test Results on Match Ratios ===\n2:1 vs 1:1      | t = 0.9650, p = 0.3345 | ❌ Not Significant\n3:1 vs 1:1      | t = 1.0150, p = 0.3101 | ❌ Not Significant\n3:1 vs 2:1      | t = 0.0501, p = 0.9600 | ❌ Not Significant\n\n\n/tmp/ipykernel_39959/955975056.py:5: FutureWarning:\n\nThe behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport pyreadstat\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_ratio = df[df['treatment'] == 1].copy()\n\ndf_ratio['ratio1'] = (df_ratio['ratio'] == 1).astype(int)\ndf_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\n\nX = df_ratio[['ratio2', 'ratio3']]  \nX = sm.add_constant(X)\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\n\nregression_summary = model.summary()\nregression_summary\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.6454\n\n\nDate:\nWed, 23 Apr 2025\nProb (F-statistic):\n0.524\n\n\nTime:\n20:32:03\nLog-Likelihood:\n16688.\n\n\nNo. Observations:\n33396\nAIC:\n-3.337e+04\n\n\nDf Residuals:\n33393\nBIC:\n-3.334e+04\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nconst\n0.0207\n0.001\n14.912\n0.000\n0.018\n0.023\n\n\nratio2\n0.0019\n0.002\n0.958\n0.338\n-0.002\n0.006\n\n\nratio3\n0.0020\n0.002\n1.008\n0.313\n-0.002\n0.006\n\n\n\n\n\n\n\n\nOmnibus:\n38963.957\nDurbin-Watson:\n1.995\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n2506478.937\n\n\nSkew:\n6.511\nProb(JB):\n0.00\n\n\nKurtosis:\n43.394\nCond. No.\n3.73\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe regression results show that neither the 2:1 nor the 3:1 match ratios led to a statistically significant increase in donation likelihood compared to the 1:1 match. While both ratio2 and ratio3 have positive coefficients, their p-values (0.338 and 0.313) are well above conventional significance thresholds. This suggests that offering a higher match doesn’t meaningfully change the probability that someone donates, at least in this context.\n\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf['ratio_str'] = df['ratio'].replace({1: '1:1', 2: '2:1', 3: '3:1'})\n\nmatch_df = df[df['treatment'] == 1][['gave', 'ratio_str']].dropna()\n\ngave_1to1 = match_df[match_df['ratio_str'] == '1:1']['gave']\ngave_2to1 = match_df[match_df['ratio_str'] == '2:1']['gave']\ngave_3to1 = match_df[match_df['ratio_str'] == '3:1']['gave']\n\nrate_1to1 = gave_1to1.mean()\nrate_2to1 = gave_2to1.mean()\nrate_3to1 = gave_3to1.mean()\n\ndiff_2_vs_1_data = rate_2to1 - rate_1to1\ndiff_3_vs_2_data = rate_3to1 - rate_2to1\n\ndf['ratio2'] = (df['ratio'] == 2).astype(int)\ndf['ratio3'] = (df['ratio'] == 3).astype(int)\nreg_df = df[df['treatment'] == 1][['gave', 'ratio2', 'ratio3']].dropna()\n\nimport statsmodels.api as sm\nX = sm.add_constant(reg_df[['ratio2', 'ratio3']])\ny = reg_df['gave']\nmodel = sm.OLS(y, X).fit()\n\ndiff_2_vs_1_reg = model.params['ratio2']\ndiff_3_vs_2_reg = model.params['ratio3'] - model.params['ratio2']\n\n{\n    \"Response Rate Difference (2:1 - 1:1) [Data]\": round(diff_2_vs_1_data, 4),\n    \"Response Rate Difference (3:1 - 2:1) [Data]\": round(diff_3_vs_2_data, 4),\n    \"Coefficient Difference (2:1 - 1:1) [Regression]\": round(diff_2_vs_1_reg, 4),\n    \"Coefficient Difference (3:1 - 2:1) [Regression]\": round(diff_3_vs_2_reg, 4)\n}\n\n/tmp/ipykernel_39959/1367793913.py:5: FutureWarning:\n\nThe behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n\n\n\n{'Response Rate Difference (2:1 - 1:1) [Data]': 0.0019,\n 'Response Rate Difference (3:1 - 2:1) [Data]': 0.0001,\n 'Coefficient Difference (2:1 - 1:1) [Regression]': 0.0019,\n 'Coefficient Difference (3:1 - 2:1) [Regression]': 0.0001}\n\n\nBased on both the direct data comparisons and the regression coefficients, the differences in response rates between match sizes are extremely small. The move from a 1:1 to a 2:1 match increases the donation rate by just 0.0019 (0.19 percentage points), and the jump from 2:1 to 3:1 adds only 0.0001 (0.01 percentage points). These effects are negligible in practice and statistically insignificant. The conclusion is clear: increasing the match ratio beyond 1:1 does not meaningfully improve donation rates. The mere presence of a match appears to matter, but making the match more generous does not lead to further increases in giving\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport pyreadstat\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_amount = df[['gave', 'amount', 'treatment']].dropna()\n\namount_treat = df_amount[df_amount['treatment'] == 1]['amount']\namount_control = df_amount[df_amount['treatment'] == 0]['amount']\nt_stat, p_value = ttest_ind(amount_treat, amount_control, nan_policy='omit')\n\nX = sm.add_constant(df_amount['treatment'])\ny = df_amount['amount']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_positive_donors = df_amount[df_amount['gave'] == 1].copy()\n\namount_treat = df_positive_donors[df_positive_donors['treatment'] == 1]['amount']\namount_control = df_positive_donors[df_positive_donors['treatment'] == 0]['amount']\nt_stat, p_value = ttest_ind(amount_treat, amount_control, nan_policy='omit')\n\nX = sm.add_constant(df_positive_donors['treatment'])\ny = df_positive_donors['amount']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\ntreatment_donors = df_positive_donors[df_positive_donors['treatment'] == 1]['amount']\ncontrol_donors = df_positive_donors[df_positive_donors['treatment'] == 0]['amount']\n\nmean_treatment = treatment_donors.mean()\nmean_control = control_donors.mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\naxes[0].hist(treatment_donors, bins=30, color='skyblue', edgecolor='black')\naxes[0].axvline(mean_treatment, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_treatment:.2f}\")\naxes[0].set_title(\"Treatment Group (Donors Only)\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].set_ylabel(\"Frequency\")\naxes[0].legend()\n\naxes[1].hist(control_donors, bins=30, color='lightgray', edgecolor='black')\naxes[1].axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_control:.2f}\")\naxes[1].set_title(\"Control Group (Donors Only)\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].legend()\n\nplt.tight_layout()\nprint(plt.show())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        20:32:03   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        20:32:04   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\n\n\n\n\nNone\n\n\nThe analysis shows that while the treatment group gave slightly more on average than the control group when everyone is included, the difference isn’t statistically significant at conventional levels. When we look only at those who actually donated, the control group gave more on average than the treatment group, and again, the difference isn’t significant. The histograms reinforce this, showing very similar distributions for both groups. This suggests that the match offer might help get more people to donate, but it doesn’t appear to influence how much they give once they’ve made the decision to contribute."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#simulation-experiment",
    "href": "blog/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\ncontrol_draws = np.random.binomial(1, 0.018, size=10000)\ntreatment_draws = np.random.binomial(1, 0.022, size=10000)\n\ndiffs = treatment_draws - control_draws\n\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences')\nplt.axhline(0.004, color='red', linestyle='--', label='True Mean Difference (0.022 - 0.018)')\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.title(\"Law of Large Numbers: Convergence of Mean Difference\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThis plot provides visual evidence of the Law of Large Numbers in action. Initially, the cumulative average of differences fluctuates significantly due to high variability in small sample comparisons. However, as the number of simulations increases, the cumulative average begins to stabilize and converge toward the true mean difference of 0.004 (i.e., 0.022 − 0.018), indicated by the red dashed line.\nBy the time we reach several thousand simulations, the cumulative average consistently hovers around the true difference, confirming that with enough observations, the sample mean reliably estimates the population mean difference. This reinforces the importance of large sample sizes when estimating small treatment effects.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nsample_sizes = [50, 200, 500, 1000]\ntrue_diff = 0.022 - 0.018\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(1000):\n        control_sample = np.random.binomial(1, 0.018, size=n)\n        treatment_sample = np.random.binomial(1, 0.022, size=n)\n        mean_diff = treatment_sample.mean() - control_sample.mean()\n        diffs.append(mean_diff)\n    \n    axes[i].hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='black', linestyle='--')\n    axes[i].axvline(true_diff, color='red', linestyle='--', label=f'True Diff = {true_diff:.4f}')\n    axes[i].set_title(f'Sample Size: {n}')\n    axes[i].legend()\n\nplt.suptitle(\"Central Limit Theorem: Sampling Distribution of Mean Differences\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIn the histogram for sample size = 50, zero is approximately in the middle of the distribution, which means that with small samples, it’s difficult to distinguish whether the treatment has a meaningful effect—the distribution is too wide, and zero is a plausible average difference just by chance.\nAs the sample size increases to 200, 500, and especially 1000, zero moves toward the tails of the distribution. This suggests that with more data, the sample differences become more precise and center more tightly around the true mean difference (0.004), making it less likely that the observed effect is due to chance. At large sample sizes, zero is no longer a likely value, reinforcing confidence that the treatment has a small but real effect."
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "This is project 2",
    "section": "",
    "text": "This is project 2"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nNivan Vora\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  }
]